{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2024 Insights - Data Collection",
   "id": "57b272f469640885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T12:08:26.697478Z",
     "start_time": "2024-12-29T12:08:26.564748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path"
   ],
   "id": "f0ea410ba01c8838",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Project Setup\n",
    "\n",
    "Before proceeding with data collection, we need to ensure that the necessary directories for storing raw and processed data are in place. This step is crucial to maintain an organized structure for our project, especially when working with multiple datasets over time.\n",
    "\n",
    "The following Python code will check if the required directories exist (`raw` and `processed` under `2024_insights`), and if not, it will create them. This approach ensures that the environment is always correctly set up before any data processing begins, even if you're running this notebook on a new machine or a fresh clone of the repository.\n"
   ],
   "id": "f67300782f9b0953"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T12:08:27.683102Z",
     "start_time": "2024-12-29T12:08:27.678286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directories to create\n",
    "dirs = [\n",
    "    \"../../data/2024_insights/raw/\",\n",
    "    \"../../data/2024_insights/processed/\",\n",
    "    \"../../data/2024_insights/output/\",\n",
    "]\n",
    "\n",
    "# Create 2024 Insights data directories if they don't exist\n",
    "for d in dirs:\n",
    "    os.makedirs(d, exist_ok=True)"
   ],
   "id": "99e5bc4542e6d1d7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "8656d56c321c5758",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "To automate the downloading, unzipping, and saving of required datasets, execute the Python code in the **next cell**.\n",
    "\n",
    "This script will:\n",
    "- Download the NIST NVD (2023 and 2024) and CISA KEV datasets.\n",
    "- Extract JSON files from ZIP archives.\n",
    "- Save all files to the directory: `/data/2024_insights/raw/`.\n",
    "\n",
    "Once the script has run successfully, proceed to the data preprocessing steps in the next notebook."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:15:07.053129Z",
     "start_time": "2024-12-28T11:15:04.282886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Target directory for raw data\n",
    "DATA_DIR = Path(\"../../data/2024_insights/raw\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# URLs for datasets\n",
    "DATASETS = {\n",
    "    \"nvdcve-1.1-2024.json.zip\": \"https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2024.json.zip\",\n",
    "    \"nvdcve-1.1-2023.json.zip\": \"https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2023.json.zip\",\n",
    "    \"known_exploited_vulnerabilities.csv\": \"https://www.cisa.gov/sites/default/files/csv/known_exploited_vulnerabilities.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "def download_file(url, dest):\n",
    "    \"\"\"Download a file from a URL to a destination.\"\"\"\n",
    "    print(f\"Downloading: {url}\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(dest, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved to: {dest}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url} - Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def unzip_file(zip_path, dest_dir):\n",
    "    \"\"\"Unzip a file to a destination directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dest_dir)\n",
    "        print(f\"Unzipped {zip_path} to {dest_dir}\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "for filename, url in DATASETS.items():\n",
    "    dest_path = DATA_DIR / filename\n",
    "\n",
    "    # Download the file\n",
    "    download_file(url, dest_path)\n",
    "\n",
    "    # If it's a ZIP file, extract its contents\n",
    "    if filename.endswith(\".zip\"):\n",
    "        unzip_file(dest_path, DATA_DIR)\n",
    "        dest_path.unlink()  # Remove the ZIP file after extraction"
   ],
   "id": "eb1fbb84fe88fb50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2024.json.zip\n",
      "Saved to: ../../data/2024_insights/raw/nvdcve-1.1-2024.json.zip\n",
      "Unzipped ../../data/2024_insights/raw/nvdcve-1.1-2024.json.zip to ../../data/2024_insights/raw\n",
      "Downloading: https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2023.json.zip\n",
      "Saved to: ../../data/2024_insights/raw/nvdcve-1.1-2023.json.zip\n",
      "Unzipped ../../data/2024_insights/raw/nvdcve-1.1-2023.json.zip to ../../data/2024_insights/raw\n",
      "Downloading: https://www.cisa.gov/sites/default/files/csv/known_exploited_vulnerabilities.csv\n",
      "Saved to: ../../data/2024_insights/raw/known_exploited_vulnerabilities.csv\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
